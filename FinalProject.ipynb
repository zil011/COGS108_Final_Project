{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see whether or not there is a significant correlation between the weather and the number of rides made per day in New York, appropriate data has been gathered and analyzed. The weather is divided into three different attributes; temperature, wind speed, and humidity, for each hour during the day in May of 2014. These three attributes were analyzed against the number of Uber rides made in each month, to see if we can visually see the correlation between these three attributes and the rides made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Zijian Liu\n",
    "- Pin-Hsuan Chen\n",
    "- Kyle Reed \n",
    "- Yunji Ryu\n",
    "- Jing Wei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A15723355\n",
    "- A14012598\n",
    "- A11839833\n",
    "- A15729483\n",
    "- A14767336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research question: How does the weather condition, specifically wind speed, temperature, humidity, and hourly weather description, affect the overall number of rides during the day in NYC?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no prior Work done for our topic. But based on our experiences with acquiring rides in certain weather conditions, there are numerous reasons why one can consider getting a taxi/Uber compared to getting there by foot or other means. One of the main components that influences this decision is weather. Engineers in the New York State created a system to provide information about the road conditions in New York State, specifically catering towards the more haphazard winter season, providing whether the highway will be blocked or not due to snow and ice operations. They also included a report for each of the observed years to include a more detailed description of the road conditions and list how accurate their report was. But not much of these affected the road conditions during the non-winter seasons. Whether it's the wind travel advisory warnings, slippery driveways on a rainy day, drivers and the riders tend to be more wary of the environmental situations around the road regardless of the season, which affects their decision to get a ride or not, conclusively affecting the number of rides that are made in New York. In order to investigate this information, we decided to use our readily available public data to analyze and infer to the possible correlations listed in our research question and hypothesis.\n",
    "\n",
    "References (include links):\n",
    "- 1) https://www.dot.ny.gov/wta (New York State Winter Travel Advisory System for 2014 - 2015 winter season)\n",
    "- 2) https://www.dot.ny.gov/divisions/engineering/technical-services/highway-data-services/traffic-data (Traffic Data Report based on various regions in New York State in 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Temperature will have an effect on ride count.\n",
    "2. Wind speed will have an effect on ride count.\n",
    "3. Humidity will have an effect on ride count.\n",
    "4. Weather description will have an effect on ride count. \n",
    "\n",
    "We predict that these factor will correlate to the number of rides in some way. It is harder to say whether it will be a negative or positive correlation because unfavorable weather conditions can include either extremely low temperatures or extremely high temperatures. However, we predict ride counts to be higher on days with unfavorable weather conditions, such as thunderstorm or rain. For instance, if for a particular hour, the wind speed, humidity, and temperature are all relatively higher compared to the whole dataset, we predict the ride count to be higher as well.\n",
    "\n",
    "We believe that unfavorable weather conditions will lead to higher ride counts because people are less willing to walk or take public transportation in those conidtions. For example, if the weather was nice and sunny, people are more willing to save money and walk a couple of blocks. However, if it was rainy and cold, there is a higher chance of people getting a ride so that they can stay dry and warm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name: Historical Hourly Weather Data 2012-2017\n",
    "- Link to the dataset: https://www.kaggle.com/selfishgene/historical-hourly-weather-data\n",
    "- Number of observations: 45253\n",
    "- Description: This dataset includes hourly weather data for 30 US cities and others, from 2012 to 2017. Each attributes of the weather is divided into separate data sources on the website; acquired from Weather API and sorted by Kaggle user 'Selfish Gene'. For the purpose of this project, we decided to focus on these four weather attributes: humidity, temperature, wind speed, and weather description. These four attributes were chosen because how hot or cool it \"feels\" outside is a result of a combination of these factors. \n",
    "    - Humidity: We will extract hourly humidity data for New York from this dataset.\n",
    "    - Temperature: We will extract hourly temperature data for New York from this dataset. We noticed that the temperatures are listed as Kelvin, we will convert this to fahrenheit so the results are easier to interpret.\n",
    "    - Wind Speed: We will extract hourly wind speed data for New York from this dataset.\n",
    "    - Weather: We will extract hourly weather description data for New York from this dataset.\n",
    "\n",
    "\n",
    "- Dataset Name: Historical Uber Rides Data May 2014\n",
    "- Link to the dataset: https://github.com/fivethirtyeight/uber-tlc-foil-response\n",
    "- Number of observations: 652435\n",
    "- description: This data includes the Uber rides in New York City in May 2014, but the raw data is base on the time, latitude and longitude of each time people use Uber. We analyzed the raw data and counted the use of Uber by hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import datetime\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy.stats import pearsonr, norm, ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset we are going to clean is the ride data. The raw ride data contains every instance of a ride, along with a timestamp of when it took place. However, this format is incompatible with the rest of our data, which are formatted with one instance per hour. What we need is to compress this dataset from individual counts to a number of counts per hour.\n",
    "\n",
    "This is not only conducive to our analysis, but also helps depersonalize the data for data privacy purposes. Each individual instance of a ride is already depersonalized, since it contains no personally identifiable information about the riders or drivers of the Uber ride, but compressing the data into hourly counts makes it even less identifiable, since not even the individual rides are distinguishable anymore.\n",
    "\n",
    "The steps we used to achieve this are as follows\n",
    "\n",
    "1. Load and read all the CSV file. We will also take a look at what the dataset looks like and how many enteries there are. Here we noticed that we need to condense our dataset in some way to match the hourly weather descriptions. \n",
    "2. Initialize a dictionary for each hour in May 2014, the month we are analyzing. This will serve as a backbone to scrape the counts from the raw data.\n",
    "3. Run through the raw data, and for each ride in the dataset add 1 to the count of rides during that respective hour in the dict\n",
    "4. Once the ride counts have been collected, save the dictionary as a csv file for later use.\n",
    "\n",
    "[Steps 2-4 are commented out here since re-running them takes a long time, and since we already have the .csv file we don't need to re-run it anyway]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 \n",
    "pickup_df = pd.read_csv('uber-raw-data-may14.csv')\n",
    "pickup_df.head()\n",
    "print(pickup_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Step 2\n",
    "counts = {}\n",
    "for date in np.arange(1,32):\n",
    "    for time in np.arange(0,24):\n",
    "        counts[\"5/{}/2014 {}\".format(date,time)] = 0\n",
    "        \n",
    "#Step 3\n",
    "for index, row in pickup_df.iterrows():\n",
    "        counts[row[0][:row[0].index(\":\")]] += 1\n",
    "\n",
    "#Step 4\n",
    "with open('uber_hourly_counts_may.csv', 'w') as f:\n",
    "    for key in counts.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key,counts[key]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next four datasets we are going to clean are for weather attributes, namely: weather description, temperature, wind speed, and humidity. After looking over the datasets and doing some calculations, we are certain that each dataset should have 744 observations along with two columns (one for datetime and one for attribute). \n",
    "\n",
    "Since we are only interested in weather data for New York in May, we will drop all the data for other cities and other months/year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps included to clean the weather description dataset are as follows:\n",
    "1. Load the CSV file. \n",
    "2. Keep only the datasets that are for New York in May."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 2)\n",
      "0\n",
      "                              datetime\n",
      "New York                              \n",
      "broken clouds                      106\n",
      "few clouds                          43\n",
      "fog                                 11\n",
      "haze                                24\n",
      "heavy intensity drizzle              1\n",
      "heavy intensity rain                27\n",
      "light intensity drizzle             10\n",
      "light rain                         149\n",
      "mist                               104\n",
      "moderate rain                       19\n",
      "overcast clouds                     61\n",
      "scattered clouds                    65\n",
      "sky is clear                       120\n",
      "thunderstorm                         2\n",
      "thunderstorm with heavy rain         1\n",
      "very heavy rain                      1\n"
     ]
    }
   ],
   "source": [
    "# Step 1 \n",
    "weather_description_df = pd.read_csv('weather_description.csv')\n",
    "\n",
    "#Step 2 \n",
    "weather_description_df = weather_description_df[['datetime','New York']]\n",
    "weather_description_df = weather_description_df[weather_description_df['datetime'].astype(str).str.contains('2014-05')]\n",
    "\n",
    "# Print to make sure we have 744 enteries and two columns after cleaning \n",
    "print(weather_description_df.shape)\n",
    "\n",
    "#checking if there are null values \n",
    "print(sum(weather_description_df['New York'].isnull()))\n",
    "\n",
    "# Calling count() on the column containing New York data to see the specific content for weather description\n",
    "description_item = weather_description_df.groupby([\"New York\"]).count()\n",
    "print(description_item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps included to clean the temperature dataset are as follows:\n",
    "1. Load the CSV file. \n",
    "2. Keep only the datasets that are for New York in May. \n",
    "3. Convert enteries in temperature from Kelvin to fahrenheit so its easier to interpret result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 2)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  New York\n",
       "13836  2014-05-01 00:00:00      51.0\n",
       "13837  2014-05-01 01:00:00      52.0\n",
       "13838  2014-05-01 02:00:00      52.0\n",
       "13839  2014-05-01 03:00:00      54.0\n",
       "13840  2014-05-01 04:00:00      53.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1 \n",
    "temperature_df = pd.read_csv('temperature.csv')\n",
    "\n",
    "#Step 2 \n",
    "temperature_df = temperature_df[temperature_df['datetime'].astype(str).str.contains('2014-05')]\n",
    "temperature_df = temperature_df[['datetime','New York']]\n",
    "\n",
    "# Print to make sure we have 744 enteries and two columns after cleaning. \n",
    "print(temperature_df.shape)\n",
    "\n",
    "#checking if there are null values \n",
    "print(sum(temperature_df['New York'].isnull()))\n",
    "\n",
    "#Step 3\n",
    "for i in temperature_df.index.values:\n",
    "    k_temp = temperature_df.loc[i,'New York']\n",
    "    f_temp = 9/5*(k_temp-273.15)+32\n",
    "    f_temp_2 = int(str(f_temp)[:2])\n",
    "    temperature_df.loc[i,'New York'] = f_temp_2\n",
    "\n",
    "temperature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps included to clean the wind speed dataset are as follows:\n",
    "1. Load the CSV file. \n",
    "2. Keep only the datasets that are for New York in May."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 2)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  New York\n",
       "13836  2014-05-01 00:00:00       4.0\n",
       "13837  2014-05-01 01:00:00       5.0\n",
       "13838  2014-05-01 02:00:00       5.0\n",
       "13839  2014-05-01 03:00:00       5.0\n",
       "13840  2014-05-01 04:00:00       4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 1\n",
    "wind_speed_df = pd.read_csv('wind_speed.csv')\n",
    "\n",
    "#Step 2 \n",
    "wind_speed_df = wind_speed_df[['datetime','New York']]\n",
    "wind_speed_df = wind_speed_df[wind_speed_df['datetime'].astype(str).str.contains('2014-05')]\n",
    "# Print to make sure we have 744 enteries and two columns after cleaning. \n",
    "print(wind_speed_df.shape)\n",
    "\n",
    "#checking if there are null values \n",
    "print(sum(wind_speed_df['New York'].isnull()))\n",
    "\n",
    "wind_speed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps included to clean the humidity dataset are as follows:\n",
    "1. Load the CSV file. \n",
    "2. Keep only the datasets that are for New York in May.\n",
    "\n",
    "We notice here that there are two NaN values in our dataset. At this point of data cleaning, we cannot just drop the NaN values because we are not yet at our final goal, which is to combine ride count data with weather data using our hourly time stamps. If we were to drop the NaN values now, when we do combine the individual dataframes, the indices of our hourly time stamps won't match up. For this reason, we've decided to change that value to -1 for now and eventually drop the NaN values when we combine everything. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 2)\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13836</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13837</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13838</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13839</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13840</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  New York\n",
       "13836  2014-05-01 00:00:00      95.0\n",
       "13837  2014-05-01 01:00:00      94.0\n",
       "13838  2014-05-01 02:00:00      95.0\n",
       "13839  2014-05-01 03:00:00      94.0\n",
       "13840  2014-05-01 04:00:00      94.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1 \n",
    "humidity_df = pd.read_csv('humidity.csv')\n",
    "\n",
    "#Step 2 \n",
    "humidity_df = humidity_df[['datetime','New York']]\n",
    "humidity_df = humidity_df[humidity_df['datetime'].astype(str).str.contains('2014-05')]\n",
    "\n",
    "# Print to make sure we have 744 enteries and two columns after cleaning. \n",
    "print(humidity_df.shape)\n",
    "\n",
    "#checking if there is null values \n",
    "print(sum(humidity_df['New York'].isnull()))\n",
    "\n",
    "#replacing null with -1 \n",
    "humidity_df['New York'] = humidity_df['New York'].replace(np.NaN, -1)\n",
    "\n",
    "humidity_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned all our datasets, we can put all the datasets into one dataframe. To do this we need to perfrom the following steps:\n",
    "1. Rename all the columns so that it correctly matches with the types of data stored. \n",
    "2. Reset the index for each dataframe so that we can join them together successfully. \n",
    "3. Join everything into one dataframe and make sure the resulting dataframe is what we would expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>description</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind speed</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime           description  temperature  wind speed  \\\n",
       "0  2014-05-01 00:00:00         moderate rain         51.0         4.0   \n",
       "1  2014-05-01 01:00:00         moderate rain         52.0         5.0   \n",
       "2  2014-05-01 02:00:00         moderate rain         52.0         5.0   \n",
       "3  2014-05-01 03:00:00  heavy intensity rain         54.0         5.0   \n",
       "4  2014-05-01 04:00:00  heavy intensity rain         53.0         4.0   \n",
       "\n",
       "   humidity  \n",
       "0      95.0  \n",
       "1      94.0  \n",
       "2      95.0  \n",
       "3      94.0  \n",
       "4      94.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1\n",
    "weather_description_df.rename(columns={'New York':'description'}, inplace=True)\n",
    "temperature_df.rename(columns={'New York':'temperature'}, inplace=True)\n",
    "wind_speed_df.rename(columns={'New York':'wind speed'}, inplace=True)\n",
    "humidity_df.rename(columns={'New York':'humidity'}, inplace=True)\n",
    "\n",
    "\n",
    "# Step 2\n",
    "weather_description_df = weather_description_df.reset_index(drop=True)\n",
    "temperature_df = temperature_df.reset_index(drop=True)\n",
    "wind_speed_df = wind_speed_df.reset_index(drop=True)\n",
    "humidity_df = humidity_df.reset_index(drop=True)\n",
    "\n",
    "#Step 3 \n",
    "# weather_description_df = weather_description_df.join(temperature_df['temperature'])\n",
    "# weather_description_df = weather_description_df.join(wind_speed_df['wind speed'])\n",
    "# weather_description_df = weather_description_df.join(humidity_df['humidity'])\n",
    "\n",
    "\n",
    "# Take a look. \n",
    "weather_description_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our weather data in a single dataframe as shown above, we can combine this with the ride count data. As mentioned earlier, we've compressed the ride data into hourly ride counts, and this is stored in a separate CSV file called 'uber_hourly_counts_may.csv'.\n",
    "\n",
    "Similar to how we cleaned and combined the weather data, we will need to perform the following steps to the ride count CSV file:\n",
    "\n",
    "1. Load the CSV file. \n",
    "2. Make sure there are 744 enteries and take a look at the data.  \n",
    "3. Rename is column to reflect the data stored and reindex to match other datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(744, 2)\n",
      "         Hour  Count\n",
      "0  5/1/2014 0    348\n",
      "1  5/1/2014 1    179\n",
      "2  5/1/2014 2    101\n",
      "3  5/1/2014 3    172\n",
      "4  5/1/2014 4    241\n"
     ]
    }
   ],
   "source": [
    "# Step 1\n",
    "ride_count_df = pd.read_csv('uber_hourly_counts_may.csv')\n",
    "\n",
    "# Step 2 \n",
    "print(ride_count_df.shape)\n",
    "print(ride_count_df.head())\n",
    "\n",
    "# Step 3\n",
    "ride_count_df.rename(columns={'Count':'Count'}, inplace=True)\n",
    "#weather_description_df = weather_description_df.join(ride_count_df['Count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rename this newly combined dataframe 'df' and make sure that it is what we expect. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>description</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind speed</th>\n",
       "      <th>humidity</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-01 00:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-01 01:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-01 02:00:00</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-05-01 03:00:00</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-05-01 04:00:00</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>53.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime           description  temperature  wind speed  \\\n",
       "0  2014-05-01 00:00:00         moderate rain         51.0         4.0   \n",
       "1  2014-05-01 01:00:00         moderate rain         52.0         5.0   \n",
       "2  2014-05-01 02:00:00         moderate rain         52.0         5.0   \n",
       "3  2014-05-01 03:00:00  heavy intensity rain         54.0         5.0   \n",
       "4  2014-05-01 04:00:00  heavy intensity rain         53.0         4.0   \n",
       "\n",
       "   humidity  Count  \n",
       "0      95.0    348  \n",
       "1      94.0    179  \n",
       "2      95.0    101  \n",
       "3      94.0    172  \n",
       "4      94.0    241  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = weather_description_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have achieved our final goal in data cleaning, we can go ahead and drop the NaN values in the humidity dataset earlier without messing up our indexing. Our decision to drop the NaN values is justified by the numerous other observations we have, meaning these two rows of data will not affect our analysis. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to change the -1 back to NaN and drop it from df\n",
    "df['humidity'] = df['humidity'].replace(-1, np.NaN)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataframe we needed, we move on to data analysis. First, we generated our our csv from the dataframe above. That line is removed so that whoever runs this notebook won't accidentally overwrite it. It won't change anything, but there is no need to re-generate the csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols_plot = ['description', 'temperature','wind speed', 'humidity']\n",
    "axes = weather_description_df[cols_plot].plot(marker='.', alpha=0.1, linestyle='None', figsize=(11, 9), subplots=True)\n",
    "for y_axis in axes:\n",
    "    y_axis.set_ylabel('counts')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Count  temperature  wind_speed    humidity   temp_diff\n",
      "count   742.000000   742.000000  742.000000  742.000000  742.000000\n",
      "mean    876.000000    61.765499    2.141509   65.951482    6.251934\n",
      "std     569.505316     7.855407    1.935583   22.689961    4.778820\n",
      "min      52.000000    46.000000    0.000000   18.000000    0.283923\n",
      "25%     396.500000    56.000000    1.000000   47.000000    2.283923\n",
      "50%     787.500000    61.000000    2.000000   64.000000    5.283923\n",
      "75%    1273.500000    66.000000    3.000000   91.000000    8.716077\n",
      "max    3076.000000    86.000000   12.000000  100.000000   23.716077\n",
      "                Count  temperature  wind_speed  humidity  temp_diff\n",
      "Count        1.000000     0.197756   -0.009203  0.022967  -0.128125\n",
      "temperature  0.197756     1.000000    0.170557 -0.401010   0.245826\n",
      "wind_speed  -0.009203     0.170557    1.000000 -0.233347   0.170131\n",
      "humidity     0.022967    -0.401010   -0.233347  1.000000  -0.326699\n",
      "temp_diff   -0.128125     0.245826    0.170131 -0.326699   1.000000\n"
     ]
    }
   ],
   "source": [
    "df = df[['datetime','Count','description','temperature','wind speed','humidity']]\n",
    "df['wind_speed'] = df['wind speed']\n",
    "df = df[['datetime','Count','description','temperature','wind_speed','humidity']]\n",
    "df['temp_diff'] = np.absolute(df['temperature'] - 62.283923)\n",
    "df.head()\n",
    "desc = df.describe()\n",
    "print(desc)\n",
    "corrs = df.corr()\n",
    "print(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplot for wind speed and ride counts \n",
    "sns.lmplot(x='wind_speed', y='Count', data=df, fit_reg=False, x_jitter=.5, y_jitter=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot for temperature and ride counts \n",
    "sns.lmplot(x='temperature', y='Count', data=df, fit_reg=False, x_jitter=.5, y_jitter=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot for humidity and ride counts\n",
    "sns.lmplot(x='humidity', y='Count', data=df, fit_reg=False, x_jitter=.5, y_jitter=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Range for humidity \n",
    "print(\"Highest humidity is\",df['humidity'].max(),\"and lowest humidity is\",df['humidity'].min())\n",
    "#Range for temperature \n",
    "print(\"Highest temperature is\",df['temperature'].max(),\"and lowest temperature is\",df['temperature'].min())\n",
    "outcome, predictors = patsy.dmatrices('Count ~ temp_diff + humidity + wind_speed', df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Count ~ temp_diff', df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Count ~ wind_speed', df)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather condition combination to ride counts \n",
    "# Comfort level according to National Weather services \n",
    "# humidity >= 65 - oppressive air condition, lots of moisture in the air \n",
    "# 55 > humidity >65 - sticky and muggy https://www.weather.gov/arx/why_dewpoint_vs_humidity\n",
    "# 87 degrees - too hot in NY https://weather.com/news/news/how-hot-is-too-hot-survey\n",
    "\n",
    "df_warm = df[df['humidity'] >= 65]\n",
    "df_warm = df[df['temperature'] > 60]\n",
    "df_warm.head()\n",
    "sns.lmplot(x='humidity', y='Count', data=df_warm, fit_reg=False, x_jitter=.5, y_jitter=.5)\n",
    "sns.lmplot(x='temperature', y='Count', data=df, fit_reg=False, x_jitter=.5, y_jitter=.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cooler = df[df['humidity'] < 65]\n",
    "df_cooler = df[df['temperature'] < 60]\n",
    "df_cooler = df_cooler[df_cooler['temperature']> 55]\n",
    "df_cooler.head()\n",
    "sns.lmplot(x='humidity', y='Count', data=df_cooler, fit_reg=False, x_jitter=.5, y_jitter=.5)\n",
    "sns.lmplot(x='temperature', y='Count', data=df_cooler, fit_reg=False, x_jitter=.5, y_jitter=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[229]\n",
    "df.iloc[640]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['temperature', 'wind_speed', 'humidity']\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "# Separating out the target\n",
    "y = df.loc[:,['description']].values\n",
    "# Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)\n",
    "pca = PCA(n_components=1)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal_component_1'])\n",
    "finalDf = pd.concat([principalDf, df[['Count']], df[['description']]], axis = 1)\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Count', fontsize = 15)\n",
    "ax.set_title('PCR', fontsize = 20)\n",
    "targets = ['light rain', 'sky is clear', 'broken clouds', 'mist', 'scattered clouds', 'overcast clouds', 'few clouds', 'heavy intensity rain','haze','moderate rain','fog','light intensity drizzle','thunderstorm','very heavy rain','thunderstorm with heavy rain','heavy intensity drizzle']\n",
    "colors = ['r', 'g', 'b', 'y', 'k', 'c', 'm', 'darkslategrey', 'wheat','orange','hotpink','navy','teal','aqua','violet','lightgreen']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf['description'] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal_component_1'], finalDf.loc[indicesToKeep, 'Count'], c = color, s = 100)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write analysis here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome, predictors = patsy.dmatrices('Count ~ principal_component_1', finalDf)\n",
    "mod = sm.OLS(outcome, predictors)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_plot = ['temperature']\n",
    "axes_temperature = weather_description_df[temperature_plot].plot(marker='.', color=\"darkgreen\",\n",
    "                                                                 alpha=0.6, \n",
    "                                                                 linestyle='None', \n",
    "                                                                 figsize=(11, 9), \n",
    "                                                                 subplots=True)\n",
    "for y_axis in axes_temperature:\n",
    "    y_axis.set_ylabel('kelvin')\n",
    "for x_axis in axes_temperature:\n",
    "    x_axis.set_xlabel('ride count for that hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed_plot = ['wind speed']\n",
    "axes_wind_speed = weather_description_df[wind_speed_plot].plot(marker='.', color=\"darkred\",\n",
    "                                                               alpha=0.6, \n",
    "                                                               linestyle='None', \n",
    "                                                               figsize=(11, 9), \n",
    "                                                               subplots=True)\n",
    "for y_axis in axes_wind_speed:\n",
    "    y_axis.set_ylabel('mph')\n",
    "for x_axis in axes_wind_speed:\n",
    "    x_axis.set_xlabel('ride count for that hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humidity_plot = ['humidity']\n",
    "axes_humidity = weather_description_df[humidity_plot].plot(marker='.', color=\"blue\",\n",
    "                                                           alpha=0.6, \n",
    "                                                           linestyle='None', \n",
    "                                                           figsize=(11, 9), \n",
    "                                                           subplots=True)\n",
    "for y_axis in axes_humidity:\n",
    "    y_axis.set_ylabel('humidity')\n",
    "    \n",
    "for x_axis in axes_humidity:\n",
    "    x_axis.set_xlabel('ride count for that hour')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include cells that describe the steps in your data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we are analyzing for this project is public data obtained from an open source. The data on its own does not reveal any private information about individual users as well as Uber drivers so we are not as concerned with personal privacy. However, analyzers could still easily extract a lot of information from these data. For instance, analyzing this data set could reveal usersâ€™ commute patterns and preferences. Though this does not point to a specific person, it could be information that could be sold to other companies for profit. From this, companies can target users based on their individual preferences. For example, they could distribute advertisements based on these preferences. Or, rideshare apps, like Uber, could take advantage of all these data and deliberately raise prices when the demand is high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is hard to parametrize how a description can effect ride count, we decided it is ambiguious to use description to predict ride count. To see the actual effect of description, we did a PCA on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
